# Ditto Talking Head API Configuration

# Backend selection: "pytorch" or "tensorrt"
DITTO_INFERENCE_BACKEND=pytorch

# Model paths (adjust based on backend)
# For PyTorch:
DITTO_CFG_PKL=checkpoints/ditto_cfg/v0.4_hubert_cfg_pytorch.pkl
DITTO_DATA_ROOT=checkpoints/ditto_pytorch
# For TensorRT, uncomment these instead:
# DITTO_CFG_PKL=checkpoints/ditto_cfg/v0.4_hubert_cfg_trt.pkl
# DITTO_DATA_ROOT=checkpoints/ditto_trt_Ampere_Plus

# Server settings
DITTO_HOST=0.0.0.0
DITTO_PORT=8000
DITTO_DEBUG=false

# GPU settings
DITTO_GPU_ID=0
DITTO_MAX_CONCURRENT_SESSIONS=2

# CORS origins (comma-separated)
DITTO_CORS_ORIGINS=http://localhost:3000,http://localhost:5173

# Logging
DITTO_LOG_LEVEL=INFO
DITTO_ENABLE_CONSOLE_LOGGING=true
DITTO_ENABLE_FILE_LOGGING=true

# Session settings
DITTO_SESSION_TIMEOUT_SECONDS=3600
DITTO_CLEANUP_INTERVAL_SECONDS=300

# Upload limits
DITTO_MAX_UPLOAD_SIZE_MB=500
